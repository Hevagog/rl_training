{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3 import PPO, DQN\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "from grid_environments.windy_gridworld import WindyGridWOrldEnv\n",
    "from algorithms.sarsa import Sarsa\n",
    "from grid_environments.cliff_env import CliffEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CliffWalking-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Sarsa(\n",
    "        gamma=0.9,\n",
    "        alpha=0.1,\n",
    "        epsilon_0=1.0,\n",
    "        epsilon_min=0.01,\n",
    "        decay_rate=0.0005,\n",
    "        action_space=env.action_space.n,\n",
    "        observation_space=env.observation_space.n,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0, Score: -7765.0\n",
      "Episode: 1000, Score: -11244.185\n",
      "Episode: 2000, Score: -1515.784\n",
      "Episode: 3000, Score: -435.987\n",
      "Episode: 4000, Score: -29.311\n",
      "Episode: 5000, Score: -22.71\n",
      "Episode: 6000, Score: -21.418\n",
      "Episode: 7000, Score: -19.133\n",
      "Episode: 8000, Score: -18.33\n",
      "Episode: 9000, Score: -17.925\n",
      "Episode: 10000, Score: -17.471\n",
      "Episode: 11000, Score: -17.429\n",
      "Episode: 12000, Score: -17.638\n",
      "Episode: 13000, Score: -17.38\n",
      "Episode: 14000, Score: -17.599\n",
      "Episode: 15000, Score: -17.324\n",
      "Episode: 16000, Score: -17.6\n",
      "Episode: 17000, Score: -17.46\n",
      "Episode: 18000, Score: -17.381\n",
      "Episode: 19000, Score: -17.379\n",
      "Episode: 20000, Score: -17.359\n",
      "Episode: 21000, Score: -17.268\n",
      "Episode: 22000, Score: -17.288\n",
      "Episode: 23000, Score: -17.685\n",
      "Episode: 24000, Score: -17.397\n",
      "Episode: 25000, Score: -17.274\n",
      "Episode: 26000, Score: -17.695\n",
      "Episode: 27000, Score: -17.291\n",
      "Episode: 28000, Score: -17.354\n",
      "Episode: 29000, Score: -17.773\n",
      "Episode: 30000, Score: -17.379\n",
      "Episode: 31000, Score: -17.595\n",
      "Episode: 32000, Score: -17.275\n",
      "Episode: 33000, Score: -17.386\n",
      "Episode: 34000, Score: -17.863\n",
      "Episode: 35000, Score: -17.494\n",
      "Episode: 36000, Score: -17.376\n",
      "Episode: 37000, Score: -17.555\n",
      "Episode: 38000, Score: -17.361\n",
      "Episode: 39000, Score: -17.512\n",
      "Episode: 40000, Score: -17.455\n",
      "Episode: 41000, Score: -17.385\n",
      "Episode: 42000, Score: -17.185\n",
      "Episode: 43000, Score: -17.595\n",
      "Episode: 44000, Score: -17.787\n",
      "Episode: 45000, Score: -17.505\n",
      "Episode: 46000, Score: -17.576\n",
      "Episode: 47000, Score: -17.459\n",
      "Episode: 48000, Score: -17.164\n",
      "Episode: 49000, Score: -17.394\n",
      "Episode: 50000, Score: -17.171\n",
      "Episode: 51000, Score: -17.482\n",
      "Episode: 52000, Score: -17.809\n",
      "Episode: 53000, Score: -17.398\n",
      "Episode: 54000, Score: -17.374\n",
      "Episode: 55000, Score: -17.565\n",
      "Episode: 56000, Score: -17.275\n",
      "Episode: 57000, Score: -17.474\n",
      "Episode: 58000, Score: -17.594\n",
      "Episode: 59000, Score: -17.188\n",
      "Episode: 60000, Score: -17.477\n",
      "Episode: 61000, Score: -17.271\n",
      "Episode: 62000, Score: -17.384\n",
      "Episode: 63000, Score: -17.558\n",
      "Episode: 64000, Score: -17.874\n",
      "Episode: 65000, Score: -17.357\n",
      "Episode: 66000, Score: -17.365\n",
      "Episode: 67000, Score: -17.292\n",
      "Episode: 68000, Score: -17.394\n",
      "Episode: 69000, Score: -17.273\n",
      "Episode: 70000, Score: -17.278\n",
      "Episode: 71000, Score: -17.491\n",
      "Episode: 72000, Score: -17.47\n",
      "Episode: 73000, Score: -17.589\n",
      "Episode: 74000, Score: -17.593\n",
      "Episode: 75000, Score: -17.282\n",
      "Episode: 76000, Score: -17.387\n",
      "Episode: 77000, Score: -17.27\n",
      "Episode: 78000, Score: -17.382\n",
      "Episode: 79000, Score: -17.302\n",
      "Episode: 80000, Score: -17.402\n",
      "Episode: 81000, Score: -17.378\n",
      "Episode: 82000, Score: -17.176\n",
      "Episode: 83000, Score: -17.689\n",
      "Episode: 84000, Score: -17.38\n",
      "Episode: 85000, Score: -17.593\n",
      "Episode: 86000, Score: -17.73\n",
      "Episode: 87000, Score: -17.309\n",
      "Episode: 88000, Score: -17.686\n",
      "Episode: 89000, Score: -17.287\n",
      "Episode: 90000, Score: -17.465\n",
      "Episode: 91000, Score: -17.427\n",
      "Episode: 92000, Score: -17.268\n",
      "Episode: 93000, Score: -17.591\n",
      "Episode: 94000, Score: -17.271\n",
      "Episode: 95000, Score: -17.202\n",
      "Episode: 96000, Score: -17.476\n",
      "Episode: 97000, Score: -17.387\n",
      "Episode: 98000, Score: -17.483\n",
      "Episode: 99000, Score: -17.682\n"
     ]
    }
   ],
   "source": [
    "history = agent.train(env, episodes=100_000, decay_epsilon=True, plot_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_sarsa = np.array(\n",
    "        [\n",
    "            np.argmax(agent.q_table[key]) \n",
    "            for key in np.arange(48)\n",
    "        ]\n",
    ").reshape(4, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_sarsa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_cliff = CliffEnv(render_mode=\"rgb_array\", size_x=6, size_y=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent2 = Sarsa(\n",
    "        gamma=0.9,\n",
    "        alpha=0.1,\n",
    "        epsilon_0=1.0,\n",
    "        epsilon_min=0.01,\n",
    "        decay_rate=0.0005,\n",
    "        action_space=env_cliff.action_space.n,\n",
    "        observation_space=env_cliff.observation_space.n,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0, Score: -100.0\n",
      "Episode: 1000, Score: -94.592\n",
      "Episode: 2000, Score: -35.43\n",
      "Episode: 3000, Score: -18.532\n",
      "Episode: 4000, Score: -9.85\n",
      "Episode: 5000, Score: -4.797\n",
      "Episode: 6000, Score: -2.262\n",
      "Episode: 7000, Score: -2.175\n",
      "Episode: 8000, Score: -1.26\n",
      "Episode: 9000, Score: -0.984\n",
      "Episode: 10000, Score: -0.711\n",
      "Episode: 11000, Score: -0.259\n",
      "Episode: 12000, Score: -0.458\n",
      "Episode: 13000, Score: -0.32\n",
      "Episode: 14000, Score: -0.609\n",
      "Episode: 15000, Score: -0.515\n",
      "Episode: 16000, Score: -0.425\n",
      "Episode: 17000, Score: -0.422\n",
      "Episode: 18000, Score: -0.401\n",
      "Episode: 19000, Score: -0.414\n",
      "Episode: 20000, Score: -0.534\n",
      "Episode: 21000, Score: -0.604\n",
      "Episode: 22000, Score: -0.438\n",
      "Episode: 23000, Score: -0.137\n",
      "Episode: 24000, Score: -0.409\n",
      "Episode: 25000, Score: -0.657\n",
      "Episode: 26000, Score: -0.442\n",
      "Episode: 27000, Score: -0.424\n",
      "Episode: 28000, Score: -0.117\n",
      "Episode: 29000, Score: -0.385\n",
      "Episode: 30000, Score: -0.116\n",
      "Episode: 31000, Score: -0.502\n",
      "Episode: 32000, Score: -0.622\n",
      "Episode: 33000, Score: -0.409\n",
      "Episode: 34000, Score: -0.335\n",
      "Episode: 35000, Score: -0.325\n",
      "Episode: 36000, Score: -0.125\n",
      "Episode: 37000, Score: -0.218\n",
      "Episode: 38000, Score: -0.418\n",
      "Episode: 39000, Score: -0.085\n",
      "Episode: 40000, Score: -0.422\n",
      "Episode: 41000, Score: -0.413\n",
      "Episode: 42000, Score: -0.206\n",
      "Episode: 43000, Score: -0.114\n",
      "Episode: 44000, Score: -0.531\n",
      "Episode: 45000, Score: -0.43\n",
      "Episode: 46000, Score: -0.247\n",
      "Episode: 47000, Score: -0.329\n",
      "Episode: 48000, Score: -0.519\n",
      "Episode: 49000, Score: -0.642\n",
      "Episode: 50000, Score: -0.203\n",
      "Episode: 51000, Score: -0.42\n",
      "Episode: 52000, Score: -0.447\n",
      "Episode: 53000, Score: -0.29\n",
      "Episode: 54000, Score: -0.438\n",
      "Episode: 55000, Score: -0.314\n",
      "Episode: 56000, Score: -0.722\n",
      "Episode: 57000, Score: -0.304\n",
      "Episode: 58000, Score: -0.432\n",
      "Episode: 59000, Score: -0.402\n",
      "Episode: 60000, Score: -0.459\n",
      "Episode: 61000, Score: -0.425\n",
      "Episode: 62000, Score: -0.604\n",
      "Episode: 63000, Score: -0.403\n",
      "Episode: 64000, Score: -0.337\n",
      "Episode: 65000, Score: -0.207\n",
      "Episode: 66000, Score: -0.209\n",
      "Episode: 67000, Score: -0.226\n",
      "Episode: 68000, Score: -0.825\n",
      "Episode: 69000, Score: -0.341\n",
      "Episode: 70000, Score: -0.523\n",
      "Episode: 71000, Score: -0.209\n",
      "Episode: 72000, Score: -0.513\n",
      "Episode: 73000, Score: -0.316\n",
      "Episode: 74000, Score: -0.426\n",
      "Episode: 75000, Score: -0.23\n",
      "Episode: 76000, Score: -0.119\n",
      "Episode: 77000, Score: -0.822\n",
      "Episode: 78000, Score: -0.09\n",
      "Episode: 79000, Score: -0.327\n",
      "Episode: 80000, Score: -0.412\n",
      "Episode: 81000, Score: -0.124\n",
      "Episode: 82000, Score: -0.222\n",
      "Episode: 83000, Score: -0.213\n",
      "Episode: 84000, Score: -0.231\n",
      "Episode: 85000, Score: -0.414\n",
      "Episode: 86000, Score: -0.508\n",
      "Episode: 87000, Score: -0.501\n",
      "Episode: 88000, Score: -0.242\n",
      "Episode: 89000, Score: -0.524\n",
      "Episode: 90000, Score: -0.235\n",
      "Episode: 91000, Score: -0.436\n",
      "Episode: 92000, Score: -0.322\n",
      "Episode: 93000, Score: -0.411\n",
      "Episode: 94000, Score: -0.201\n",
      "Episode: 95000, Score: -0.323\n",
      "Episode: 96000, Score: -0.333\n",
      "Episode: 97000, Score: -0.648\n",
      "Episode: 98000, Score: -0.331\n",
      "Episode: 99000, Score: -0.116\n"
     ]
    }
   ],
   "source": [
    "history_2 = agent2.train(env_cliff, episodes=100_000, decay_epsilon=True, plot_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 4)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent2.q_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_sarsa_2 = np.array(\n",
    "        [\n",
    "            np.argmax(agent2.q_table[key]) \n",
    "            for key in np.arange(30)\n",
    "        ]\n",
    ").reshape(6,5)\n",
    "policy_sarsa_2[env_cliff._cliff] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  1,  0,  0,  0],\n",
       "       [-1,  1,  1,  0,  0],\n",
       "       [-1,  1,  1,  0,  0],\n",
       "       [-1,  1,  0,  0,  0],\n",
       "       [-1,  0,  0,  0,  0],\n",
       "       [ 0,  3,  3,  3,  3]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_sarsa_2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
